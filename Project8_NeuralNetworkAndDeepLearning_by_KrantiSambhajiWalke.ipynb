{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SET: SVHN_single_grey1.h5\n",
    "### Author: Kranti Sambhaji Walke\n",
    "### Data Description:\n",
    "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data formatting but comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ● Data fetching and understand the train/val/test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Read and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f=h5py.File('SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ● Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Load Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train and test data\n",
    "\n",
    "X_train=h5f['X_train'][:]\n",
    "y_train=h5f['y_train'][:]\n",
    "X_test=h5f['X_test'][:]\n",
    "y_test=h5f['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  6\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[1], cmap='gray')    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[2], cmap='gray')    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Visualizing the first 10 images in the dataset and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(32, 32), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert output label to multiple values\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[1], cmap='gray')    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF0hJREFUeJztnV+MlGWWxp8jQjdI86dpaJFGUUKiZHRQO8TEzcSd2Z24ZhI12ZnohfHCDJPNmKzJ7IVxk9VN9sLZrBovNq64kmE2rn921EhGszvGzMbMjWPrIuKgggQQaeiGbugGGxE4e1EfSdPWearqreqvGt/nlxCa79T7fafe+h6q+n3qnNfcHUKI/Lio3QkIIdqDxC9Epkj8QmSKxC9Epkj8QmSKxC9Epkj8QmSKxC9Epkj8QmTKxc0MNrNbATwJYBaAf3f3R9nju7u7va+vLzoXu04TWU4/7FuS05E7u97Zs2erHj9z5kw45uKL49tg1qxZ9SdWRx4s99RYSh6nT59ueEytWMrrAsSvTcpzPnr0KE6cOFHXTZcsfjObBeBfAfwlgP0A3jWzLe7+p2hMX18fXn/99eqJkBtw9uzZVY9fdFHrP7ikvPCp4mfPmYn166+/DmMTExNVjx89ejQc09PTE8YWL14cxhjHjx+vepw9r5MnT4Yx9pwZ0XyMjIyEY6LcAeCrr74KYyzH8fHxMHbixImqx9l8RPfc008/HY6ZSjPqWQ9gl7vvdvdTAF4AcHsT5xNClEgz4l8B4PNJ/95fHBNCXAA0I/5qn2e/8VnEzDaY2YCZDbCPWkKIcmlG/PsBrJz07z4AB6Y+yN03unu/u/d3d3c3cTkhRCtpRvzvAlhjZlea2RwAdwHY0pq0hBDTTfJqv7ufNrP7AfwPKlbfJnf/iI0xs9A6Yivfc+bMqXo8dbWfXavV1lzqij5bVWZE4yLHpNa1xsbGwlj0ugDA3Llzw1jEggULwhh7rdk8Rvmz/E6dOhXG2Io+sw/Zyn3kLkROBaOzs7Puxzbl87v7GwDeaOYcQoj2oG/4CZEpEr8QmSLxC5EpEr8QmSLxC5EpTa32N4qZhfZQSkXUdFh9qVVsEcz+YVYOKwRhRTqRtcWKVZi1xayjJUuWhLHe3t6qxy+55JJwzLx588IYe12Y/RY9N2YPdnR0hLHU6lN2vRSrL9ILs3Snond+ITJF4hciUyR+ITJF4hciUyR+ITKl1NV+BmuflbJiy1Ze2bWYgxCtsLLzsVX7oaGhMHbo0KGkcVHPhKhVFAB8+eWXYYytwK9evTqMRa/NpZdeGo5hrxl7XZhbERUtMReGkdJurlYsun9S3INGHDC98wuRKRK/EJki8QuRKRK/EJki8QuRKRK/EJlSutUX2WWssCeyclK3cEolsmSYVTY8PBzG9uzZE8Y+++yzMLZ3794wNjo6WvU4K+xh9tCyZcvCGJv/qICnq6srHMOKiFhhD7P6WmGJTYZZfSzGiAqJ2PzK6hNCJCPxC5EpEr8QmSLxC5EpEr8QmSLxC5EpTVl9ZrYHwDiAMwBOu3t/6rlYlVVk5bAxzHZhdgirpIp6xTEb7eDBg2Fs9+7dYezTTz8NY8wiPHLkSNXjbEsuVrnH+uMxay6y9Fh/PGbZsd5/rKoypXov1bJjMKuykb5754isvka2m2vFs/xzdz/cgvMIIUpEH/uFyJRmxe8Afmdm75nZhlYkJIQoh2Y/9t/s7gfMbBmAN83sY3d/e/IDiv8UNgBAX19fk5cTQrSKpt753f1A8fcQgFcBrK/ymI3u3u/u/WyTByFEuSSL38wuMbOucz8D+CGA7a1KTAgxvTTzsb8XwKuFtXAxgP909/9mA8wstFGYpdTq6j1mraQ08EyxBwHeVJNtycWagrLrRbD5PXnyZBhjNmZkA7L5ZQ1Zly5dGsaiLeCA+LVhdh7Lg80vuw9StqNjNGLpRSSL3913A/hu0xkIIdqCrD4hMkXiFyJTJH4hMkXiFyJTJH4hMqXUBp5mFtpszF6JKrPYGFZFlWINAbElw86XWiHGLDF2vRTbaP78+Ul5HDt2LIzt27ev6nFWCbhgwYIwxhp/psw/uz/YPcAqD1Mt35QKvdQGpOedo+kzCCEuSCR+ITJF4hciUyR+ITJF4hciU0rfriuCrV5GDgFbDU0tfEgpImJ94lILQRgsx2gVm/XAY1tyMVjxUVQQxPodsm3PUrYGA9IKjFi/QxZj7hMjcmhYjlGskXtK7/xCZIrEL0SmSPxCZIrEL0SmSPxCZIrEL0SmlGr1nTlzJuxbxyyxyDZi1gorqGF2DSsuiRgeHg5jBw4cCGOsF9/Y2FjSOSOr56qrrgrHXH311WGMzdXOnTvDWPSaMTvv8OF446doGzIA6O3tDWMLFy6sepxtG8b6FrJiJmb5sns1srJZr8loi7VGCn70zi9Epkj8QmSKxC9Epkj8QmSKxC9Epkj8QmRKTavPzDYB+BGAIXf/TnGsG8CLAFYB2APgJ+4+Ol1JRvYF61fHqsDYNlnMrpmYmKh6PNWiYhVu0bUA3kcu5XysKi6ylADeOy+a45RejbVijMguY7kzezO1gpPdj1GM9RmMcmykKrWed/5fAbh1yrEHAbzl7msAvFX8WwhxAVFT/O7+NoCRKYdvB7C5+HkzgDtanJcQYppJ/Z2/190HAaD4O60bhBCibUz7gp+ZbTCzATMbGBmZ+gFCCNEuUsV/yMyWA0Dx91D0QHff6O797t7f3d2deDkhRKtJFf8WAPcWP98L4LXWpCOEKIt6rL7nAdwCoMfM9gN4GMCjAF4ys/sA7APw43ouZmahfcFsu8jqY1VPqc09mRUVWWyskopVj7Ftsnp6esIYqzqLrCh2rblz5zZ8PoDPVVS9x2zW1OaYLJbSkDXlHgDS76sox5SGoI0835rid/e7g9AP6r6KEGLGoW/4CZEpEr8QmSLxC5EpEr8QmSLxC5EppTbwZFZfyr51zNZg9htr7skqqaLYkiVLwjGrVq0KY4sXLw5jUeNJgO+tF9lll19+eThm0aJFYWx0NC7WZPMfVbgxmzK1Ko69Zikw25nFUu4dFkvdy7Fe9M4vRKZI/EJkisQvRKZI/EJkisQvRKZI/EJkSqlWHxDbGsyai6r32BhmrXR2doYxRtTMklmHzLJjVWysKejQUNg+IayaY3mwqj52rRTbi819aow144zyYNZhagUhy4NVoDayv14r0Tu/EJki8QuRKRK/EJki8QuRKRK/EJlS6mq/uyf1wUsp3GDnS93mK8qDbXfF8mCFLGwFnq0qR4U47HmNj4+HMbbdGCvSifJnxUzLly8PY0uXLm34WkBcHMPuAda3MKUnIND6+zuikWIgvfMLkSkSvxCZIvELkSkSvxCZIvELkSkSvxCZUs92XZsA/AjAkLt/pzj2CICfAhguHvaQu79R61zuTm2UMMmgcIbZLiwWbSUFtH7rJ1bQwc7H7DxWSBTZb8zO27dvXxjbuXNnGBseHg5jUSFOV1dXOIb1EmR2HrPtoufNbFa2pRgjtUAnsudSt/+ql3qy/RWAW6scf8Ld1xV/agpfCDGzqCl+d38bwEgJuQghSqSZ3/nvN7NtZrbJzOKvbQkhZiSp4n8KwGoA6wAMAngseqCZbTCzATMbYF8VFUKUS5L43f2Qu59x97MAngGwnjx2o7v3u3s/29xCCFEuSeI3s8kVGHcC2N6adIQQZVGP1fc8gFsA9JjZfgAPA7jFzNYBcAB7APysnou5e2ixMNsrsgeZ5ZVa1RdVHbJxrCqLXYtVxR0/fjyMjY2NhbGo9x/rxffJJ5+EsV27doWxiYmJMLZy5cqqxxcsWBCOYVZfR0dHGGOvWdQnkVnOzAZM7cWXUrnH8ohi7H6bSk3xu/vdVQ4/W/cVhBAzEn3DT4hMkfiFyBSJX4hMkfiFyBSJX4hMKX27rqgaKaVCj9ka02EDRrmnNulk1WPMzjt27FgYi6rYDh48GI7Zv39/GDtw4EAYY897zZo1VY+zL3qx5p7RVmm18ohsQFYVx+4dZvUxO49VaUb3N7Mjy6rqE0J8C5H4hcgUiV+ITJH4hcgUiV+ITJH4hciU0vfqS7EoIvuNWTwslrK3G5Bmr7CKM1bVx5qMRpVqQGwtMuuQNfdkz5ntURjZdmzPvWXLloWxnp6eMMZs4mj+p8NGS91fMcVCTrHMv3H+uh8phPhWIfELkSkSvxCZIvELkSkSvxCZUupqv5mFvdjY6jZbMY9gRRZsVZb1kYs4evRoGBsdHQ1jn3/+eRjbunVrGPv444/D2MhI4/ursPlYu3ZtGLv22mvD2DXXXFP1OCvQYY4EG8fyj0gt0EndIi7FXWCuQ+QEMLfqG+eo+5FCiG8VEr8QmSLxC5EpEr8QmSLxC5EpEr8QmVLPdl0rAfwawKUAzgLY6O5Pmlk3gBcBrEJly66fuHvsa1XOFfZHY4UPka3BrJXUHn4pW28xK5L124u21gJ4z70vvvgijEVW3/z588Mxq1atCmORZQcA1113XRjr6+urepwVAzE7j8H6LrIiqAh2D6TagMy2i8al5lEv9bzznwbwC3e/BsBNAH5uZmsBPAjgLXdfA+Ct4t9CiAuEmuJ390F3f7/4eRzADgArANwOYHPxsM0A7piuJIUQraeh3/nNbBWA6wG8A6DX3QeByn8QAOJibCHEjKNu8ZvZfAAvA3jA3ePvYX5z3AYzGzCzgSNHjqTkKISYBuoSv5nNRkX4z7n7K8XhQ2a2vIgvB1B1A3h33+ju/e7ezzZsEEKUS03xW6VS4FkAO9z98UmhLQDuLX6+F8BrrU9PCDFd1FPVdzOAewB8aGbnSs0eAvAogJfM7D4A+wD8uNaJzIxWU0VEFVHsXCwWVRYC3DaKLL2JiYlwDKtWZNt1MYsqpUKM9QtkVt+NN96YNC7qx8eqzpgNyCr3mMUWvZ4sj9T+fsyuZkS5MLs6ulYjVX01xe/ufwAQnfEHdV9JCDGj0Df8hMgUiV+ITJH4hcgUiV+ITJH4hciU0ht4RhYcs2sasS/qIcVCAWKrj9k/rOKPWYTMmkvZros9r66urjDW3d0dxlK2p2I2WpQ7O18tonsn9Z5KrdxLqcJj14p0pAaeQoiaSPxCZIrEL0SmSPxCZIrEL0SmSPxCZErpVh9rnhnBLKCUMSnNQoHYtkut3GM2ILN5mMUWWT1sD0JWAclyZM8tyoPNL3teqc0sozw6OzvDMcyOZK91qg3YSlgOU9E7vxCZIvELkSkSvxCZIvELkSkSvxCZUupqPxCvRrJV5ZSCGlbgMDYWdx5PiQ0PD4djWLtytnLMYIVJ0bZcixcvTroW226MrSwfP3684WuxAiPmVqS4N2y1nzkSqSv6Kdt1MaL7W6v9QoiaSPxCZIrEL0SmSPxCZIrEL0SmSPxCZEpNq8/MVgL4NYBLAZwFsNHdnzSzRwD8FMA5n+shd3+Dnevs2bNhwQ3bJitlyyVW7MF64DFLJrL6RkdHwzGHDx8OY2wcizEbLbKpWL/AgwcPhjE2j2x7rWgcO9/ChQvD2NKlS5PGRTYgs/pYoRMr+mH3Y6t7VEbna8Tqq8fnPw3gF+7+vpl1AXjPzN4sYk+4+7/UfTUhxIyhnr36BgEMFj+Pm9kOACumOzEhxPTS0O/8ZrYKwPUA3ikO3W9m28xsk5mlfYVMCNEW6ha/mc0H8DKAB9x9DMBTAFYDWIfKJ4PHgnEbzGzAzAbYV12FEOVSl/jNbDYqwn/O3V8BAHc/5O5n3P0sgGcArK821t03unu/u/cvWbKkVXkLIZqkpvitshT5LIAd7v74pOPLJz3sTgDbW5+eEGK6qGe1/2YA9wD40My2FsceAnC3ma0D4AD2APhZPRdM6WWWslUTG8OsFWYDRuOYjcYq91g1ILPf2LgItv0Xiw0ODoaxlGo61qeP2XkrVsRrzL29vWEs2m6so6MjHMOqCxkpdjXQ+q286qWe1f4/AKh211NPXwgxs9E3/ITIFIlfiEyR+IXIFIlfiEyR+IXIlNIbeKY0HoxsEtbIMnV7J2bJRDky+5LZgMxiY1thsaaaEWyumB3JKtxS7FRWCXjZZZeFMbb9Gmv+GhE1OgX4/cHmg8Hs5eieY9eKcmykQlDv/EJkisQvRKZI/EJkisQvRKZI/EJkisQvRKbMmL36mEURVYil2INAehXe+Ph41eOsoSaz7Jh9xeYjxWJjlWqp88gszqjRJdsHL9UWZZWY0TlZI04Ge13YfLDnHdl2zOqbN29eQ+eqmlPdjxRCfKuQ+IXIFIlfiEyR+IXIFIlfiEyR+IXIlBlj9TFS9vdj1hCDjYuqx5glw9qVM6uPNbpkOUa5sCo2ZlGlVrhFrzM734IFC8IYa+7Z09MTxqL5X7w43mOGzX1KA1qA36uRfciuFdmb7DpT0Tu/EJki8QuRKRK/EJki8QuRKRK/EJlSc7XfzDoBvA2go3j8b9z9YTO7EsALALoBvA/gHnenzdROnz6NkZGRqrGUAhJWnMFcBbbinLJd16JFi8IxV1xxRRhjq9tsRZ/l39nZWfU46+HHVu3ZOEbKCjYrfokKWQC+2h9t5cXOl9I7D+DuTcr9ze7FFAdsKvW8838F4Pvu/l1UtuO+1cxuAvBLAE+4+xoAowDuq/uqQoi2U1P8XuFczers4o8D+D6A3xTHNwO4Y1oyFEJMC3X9zm9ms4odeocAvAngMwBH3f3c5+79AOJtVIUQM466xO/uZ9x9HYA+AOsBXFPtYdXGmtkGMxsws4HR0dH0TIUQLaWh1X53PwrgfwHcBGCRmZ1bDeoDcCAYs9Hd+929n32lUghRLjXFb2ZLzWxR8fNcAH8BYAeA3wP46+Jh9wJ4bbqSFEK0nnp8nOUANpvZLFT+s3jJ3X9rZn8C8IKZ/ROA/wPwbK0TnTp1Cnv37q0aS9kWivWyYxZVioUCAB0dHVWPL1y4MBzDYPkzG5M9t6hXH9smi/X3Y/YbsyNZX8MU2FyxQpwo/5TXuVYezF5m14tg90DKtndTqSl+d98G4Poqx3ej8vu/EOICRN/wEyJTJH4hMkXiFyJTJH4hMkXiFyJTLKWnXvLFzIYBnPP6egAcLu3iMcrjfJTH+VxoeVzh7nHDw0mUKv7zLmw24O79bbm48lAeykMf+4XIFYlfiExpp/g3tvHak1Ee56M8zudbm0fbfucXQrQXfewXIlPaIn4zu9XMPjGzXWb2YDtyKPLYY2YfmtlWMxso8bqbzGzIzLZPOtZtZm+a2c7i72lvfhDk8YiZfVHMyVYzu62EPFaa2e/NbIeZfWRmf1scL3VOSB6lzomZdZrZH83sgyKPfyyOX2lm7xTz8aKZxSWG9eDupf4BMAuVNmBXAZgD4AMAa8vOo8hlD4CeNlz3ewBuALB90rF/BvBg8fODAH7ZpjweAfB3Jc/HcgA3FD93AfgUwNqy54TkUeqcADAA84ufZwN4B5UGOi8BuKs4/m8A/qaZ67TjnX89gF3uvtsrrb5fAHB7G/JoG+7+NoCpPcxvR6URKlBSQ9Qgj9Jx90F3f7/4eRyVZjErUPKckDxKxStMe9Pcdoh/BYDPJ/27nc0/HcDvzOw9M9vQphzO0evug0DlJgSwrI253G9m24pfC0rtvWZmq1DpH/EO2jgnU/IASp6TMprmtkP81VqQtMtyuNndbwDwVwB+bmbfa1MeM4mnAKxGZY+GQQCPlXVhM5sP4GUAD7j7WFnXrSOP0ufEm2iaWy/tEP9+ACsn/Tts/jnduPuB4u8hAK+ivZ2JDpnZcgAo/h5qRxLufqi48c4CeAYlzYmZzUZFcM+5+yvF4dLnpFoe7ZqT4toNN82tl3aI/10Aa4qVyzkA7gKwpewkzOwSM+s69zOAHwLYzkdNK1tQaYQKtLEh6jmxFdyJEubEKg3pngWww90fnxQqdU6iPMqek9Ka5pa1gjllNfM2VFZSPwPw923K4SpUnIYPAHxUZh4Ankfl4+PXqHwSug/AEgBvAdhZ/N3dpjz+A8CHALahIr7lJeTxZ6h8hN0GYGvx57ay54TkUeqcALgOlaa421D5j+YfJt2zfwSwC8B/Aeho5jr6hp8QmaJv+AmRKRK/EJki8QuRKRK/EJki8QuRKRK/EJki8QuRKRK/EJny/5SYPDAYEHswAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[2], cmap='gray')    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 32, 32) => (n, 1024)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (42000, 10) (18000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ● Implement and apply an optimal k-Nearest Neighbor (kNN) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH = KNeighborsClassifier(n_neighbors= 10 , weights = 'distance')\n",
    "NNH.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1024)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = NNH.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ● Print the classification metric report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.33      0.47      1814\n",
      "           1       0.79      0.43      0.56      1828\n",
      "           2       0.94      0.27      0.42      1803\n",
      "           3       0.85      0.15      0.26      1719\n",
      "           4       0.93      0.42      0.58      1812\n",
      "           5       0.88      0.15      0.25      1768\n",
      "           6       0.82      0.17      0.28      1832\n",
      "           7       0.94      0.45      0.61      1808\n",
      "           8       0.77      0.13      0.22      1812\n",
      "           9       0.91      0.20      0.32      1804\n",
      "\n",
      "   micro avg       0.87      0.27      0.41     18000\n",
      "   macro avg       0.87      0.27      0.40     18000\n",
      "weighted avg       0.87      0.27      0.40     18000\n",
      " samples avg       0.27      0.27      0.27     18000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2702222222222222\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = list(range(1,9))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 1\n"
     ]
    }
   ],
   "source": [
    "ac_scores = []\n",
    "\n",
    "# perform accuracy metrics for values from 1,3,5....19\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response\n",
    "    y_pred = knn.predict(X_test)\n",
    "    # evaluate accuracy\n",
    "    scores = accuracy_score(y_test, y_pred)\n",
    "    ac_scores.append(scores)\n",
    "\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in ac_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45916666666666667\n"
     ]
    }
   ],
   "source": [
    "#Use k=1 as the final model for prediction\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the response\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "#print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45916666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:197: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:197: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNH1 = KNeighborsClassifier(n_neighbors= 1 , weights = 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNH1.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Response and evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4677222222222222\n"
     ]
    }
   ],
   "source": [
    "# predict the response\n",
    "y_pred = NNH1.predict(X_test_scaled)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.4677222222222222\n"
     ]
    }
   ],
   "source": [
    "print(NNH1.score(X_train_scaled, y_train))\n",
    "print(NNH1.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ● Implement batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (42000, 10) (18000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Batch Normalization (with RELU activations)\n",
    "Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch normalization layer is usually inserted after dense/convolution and before nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model1 = Sequential()\n",
    "    \n",
    "    model1.add(Dense(400, input_shape = (1024, )))\n",
    "    model1.add(BatchNormalization())                    \n",
    "    model1.add(Activation('relu'))    \n",
    "    model1.add(Dense(300))\n",
    "    model1.add(BatchNormalization())                    \n",
    "    model1.add(Activation('relu'))    \n",
    "    model1.add(Dense(200))\n",
    "    model1.add(BatchNormalization())                    \n",
    "    model1.add(Activation('relu'))    \n",
    "    model1.add(Dense(200))\n",
    "    model1.add(BatchNormalization())                    \n",
    "    model1.add(Activation('relu'))    \n",
    "    model1.add(Dense(10))\n",
    "    model1.add(Activation('softmax'))\n",
    "    \n",
    "    \n",
    "    model1.compile(optimizer = 'adam', loss = 'MSE', metrics = ['accuracy'])\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 13s 315us/step - loss: 0.0547 - accuracy: 0.5700\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 6s 144us/step - loss: 0.0381 - accuracy: 0.7200\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 6s 143us/step - loss: 0.0326 - accuracy: 0.7621\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 6s 141us/step - loss: 0.0290 - accuracy: 0.7909\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 6s 143us/step - loss: 0.0270 - accuracy: 0.8051\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0256 - accuracy: 0.8172\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.0238 - accuracy: 0.8310\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 8s 180us/step - loss: 0.0227 - accuracy: 0.8384\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 8s 187us/step - loss: 0.0215 - accuracy: 0.8470\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0207 - accuracy: 0.8541\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 0.0193 - accuracy: 0.8644\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 8s 183us/step - loss: 0.0190 - accuracy: 0.8661\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 0.0181 - accuracy: 0.8731\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.0172 - accuracy: 0.8797\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 9s 216us/step - loss: 0.0168 - accuracy: 0.8830\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 8s 183us/step - loss: 0.0161 - accuracy: 0.8885\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 0.0155 - accuracy: 0.8927\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 7s 170us/step - loss: 0.0150 - accuracy: 0.8975\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 9s 215us/step - loss: 0.0143 - accuracy: 0.9022\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 8s 188us/step - loss: 0.0142 - accuracy: 0.9024\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.0135 - accuracy: 0.90690s - loss: 0.0135 - ac\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0132 - accuracy: 0.9087\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0127 - accuracy: 0.9140\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0122 - accuracy: 0.9170\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 8s 183us/step - loss: 0.0119 - accuracy: 0.9186\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 7s 178us/step - loss: 0.0116 - accuracy: 0.9217\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 7s 178us/step - loss: 0.0114 - accuracy: 0.9235\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 8s 191us/step - loss: 0.0111 - accuracy: 0.9257\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 8s 182us/step - loss: 0.0109 - accuracy: 0.9261\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 8s 182us/step - loss: 0.0106 - accuracy: 0.9289\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 0.0103 - accuracy: 0.9305\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.0099 - accuracy: 0.9329\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 10s 233us/step - loss: 0.0100 - accuracy: 0.9321\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 8s 180us/step - loss: 0.0094 - accuracy: 0.9373\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 8s 185us/step - loss: 0.0093 - accuracy: 0.9375\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 8s 191us/step - loss: 0.0092 - accuracy: 0.9378\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 7s 172us/step - loss: 0.0091 - accuracy: 0.9385\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 0.0087 - accuracy: 0.9425\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 8s 188us/step - loss: 0.0087 - accuracy: 0.9410\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 8s 182us/step - loss: 0.0084 - accuracy: 0.9436\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 8s 180us/step - loss: 0.0083 - accuracy: 0.9453\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 8s 200us/step - loss: 0.0082 - accuracy: 0.9453\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 9s 215us/step - loss: 0.0079 - accuracy: 0.9482\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 10s 245us/step - loss: 0.0075 - accuracy: 0.9502\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 9s 219us/step - loss: 0.0077 - accuracy: 0.9490\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 9s 203us/step - loss: 0.0076 - accuracy: 0.9503\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 9s 209us/step - loss: 0.0073 - accuracy: 0.9514\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 10s 236us/step - loss: 0.0074 - accuracy: 0.9511\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 9s 204us/step - loss: 0.0071 - accuracy: 0.9527\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 9s 221us/step - loss: 0.0070 - accuracy: 0.9542\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 9s 207us/step - loss: 0.0068 - accuracy: 0.9546\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 11s 266us/step - loss: 0.0069 - accuracy: 0.9551\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 9s 216us/step - loss: 0.0067 - accuracy: 0.9554\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 10s 227us/step - loss: 0.0065 - accuracy: 0.9575\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 9s 220us/step - loss: 0.0065 - accuracy: 0.9577\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 8s 192us/step - loss: 0.0060 - accuracy: 0.9608\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 8s 195us/step - loss: 0.0061 - accuracy: 0.9605\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 8s 185us/step - loss: 0.0059 - accuracy: 0.9621\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 8s 181us/step - loss: 0.0063 - accuracy: 0.9585\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 8s 188us/step - loss: 0.0061 - accuracy: 0.9600\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 8s 200us/step - loss: 0.0058 - accuracy: 0.9626\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 9s 208us/step - loss: 0.0058 - accuracy: 0.9617\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 9s 207us/step - loss: 0.0059 - accuracy: 0.9615\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 9s 203us/step - loss: 0.0056 - accuracy: 0.9640\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 8s 199us/step - loss: 0.0054 - accuracy: 0.9656\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 8s 198us/step - loss: 0.0058 - accuracy: 0.9622\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 8s 194us/step - loss: 0.0057 - accuracy: 0.9636\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 8s 197us/step - loss: 0.0056 - accuracy: 0.96420s - loss:\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 8s 193us/step - loss: 0.0054 - accuracy: 0.9647\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 9s 205us/step - loss: 0.0053 - accuracy: 0.9658\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 8s 188us/step - loss: 0.0051 - accuracy: 0.9670\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 8s 185us/step - loss: 0.0053 - accuracy: 0.9660\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 8s 185us/step - loss: 0.0050 - accuracy: 0.9676\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 8s 186us/step - loss: 0.0052 - accuracy: 0.9671\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 9s 210us/step - loss: 0.0052 - accuracy: 0.96580s - loss: 0.0052 - accuracy: 0.96\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 9s 222us/step - loss: 0.0050 - accuracy: 0.9670\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 8s 202us/step - loss: 0.0049 - accuracy: 0.9684\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 7s 178us/step - loss: 0.0050 - accuracy: 0.9680\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 8s 186us/step - loss: 0.0049 - accuracy: 0.9691\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 8s 188us/step - loss: 0.0048 - accuracy: 0.9698\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 10s 229us/step - loss: 0.0047 - accuracy: 0.9695\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 11s 274us/step - loss: 0.0045 - accuracy: 0.9710\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 11s 270us/step - loss: 0.0049 - accuracy: 0.9686\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 8s 191us/step - loss: 0.0045 - accuracy: 0.9710\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 8s 189us/step - loss: 0.0045 - accuracy: 0.9712\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 8s 196us/step - loss: 0.0045 - accuracy: 0.9710\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 8s 184us/step - loss: 0.0042 - accuracy: 0.9724\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 8s 184us/step - loss: 0.0042 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 8s 185us/step - loss: 0.0043 - accuracy: 0.97261s\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 8s 191us/step - loss: 0.0041 - accuracy: 0.9743\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 8s 180us/step - loss: 0.0046 - accuracy: 0.9707\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 8s 184us/step - loss: 0.0044 - accuracy: 0.9720\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 8s 179us/step - loss: 0.0043 - accuracy: 0.9717\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 8s 181us/step - loss: 0.0040 - accuracy: 0.9749\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 8s 186us/step - loss: 0.0041 - accuracy: 0.9739\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 8s 184us/step - loss: 0.0041 - accuracy: 0.9735\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 8s 182us/step - loss: 0.0040 - accuracy: 0.9747\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 8s 181us/step - loss: 0.0040 - accuracy: 0.9743\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 8s 193us/step - loss: 0.0037 - accuracy: 0.9764\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 9s 209us/step - loss: 0.0038 - accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "model1 = mlp_model()\n",
    "history = model1.fit(X_train, y_train, batch_size=100 , epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 5s 251us/step\n"
     ]
    }
   ],
   "source": [
    "results1 = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8559444546699524\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model2 = Sequential()\n",
    "    \n",
    "    model2.add(Dense(400, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(rate=1))\n",
    "    model2.add(Dense(300, kernel_initializer='he_normal'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))    \n",
    "    model2.add(Dropout(rate=1))\n",
    "    model2.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(rate=1))\n",
    "    model2.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(rate=1))\n",
    "    model2.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model2.add(Activation('softmax'))\n",
    "    \n",
    "    \n",
    "    model2.compile(optimizer = 'adam', loss = 'MSE', metrics = ['accuracy'])\n",
    "    \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 8s 200us/step - loss: 0.0547 - accuracy: 0.5692\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0374 - accuracy: 0.7258\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0323 - accuracy: 0.7657\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 7s 170us/step - loss: 0.0291 - accuracy: 0.7913\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0268 - accuracy: 0.8087\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 0.0252 - accuracy: 0.8182\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 7s 172us/step - loss: 0.0235 - accuracy: 0.8325\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 0.0225 - accuracy: 0.8392\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0211 - accuracy: 0.8516\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 0.0205 - accuracy: 0.8548\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0197 - accuracy: 0.8626\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0187 - accuracy: 0.8685\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.0177 - accuracy: 0.8769\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0173 - accuracy: 0.8803\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0166 - accuracy: 0.8852\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0160 - accuracy: 0.8885\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0152 - accuracy: 0.8958\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0149 - accuracy: 0.8970\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0145 - accuracy: 0.9007\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.0135 - accuracy: 0.9080\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0133 - accuracy: 0.9085\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0131 - accuracy: 0.9100\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0127 - accuracy: 0.9136\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.0124 - accuracy: 0.9162\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 7s 172us/step - loss: 0.0120 - accuracy: 0.9182\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0117 - accuracy: 0.9216\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 0.0112 - accuracy: 0.9240\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0111 - accuracy: 0.9250\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0106 - accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 7s 166us/step - loss: 0.0103 - accuracy: 0.9302\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0102 - accuracy: 0.9307\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0099 - accuracy: 0.9327\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 7s 166us/step - loss: 0.0095 - accuracy: 0.9364\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0095 - accuracy: 0.9366\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.0094 - accuracy: 0.9373\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.0089 - accuracy: 0.9414\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.0090 - accuracy: 0.9392\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 7s 166us/step - loss: 0.0086 - accuracy: 0.9427\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 0.0083 - accuracy: 0.9445\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 0.0084 - accuracy: 0.9443\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 0.0081 - accuracy: 0.9461\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0080 - accuracy: 0.9467\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0076 - accuracy: 0.9496\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.0077 - accuracy: 0.9495\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 0.0075 - accuracy: 0.9504\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 8s 190us/step - loss: 0.0075 - accuracy: 0.9502\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 8s 184us/step - loss: 0.0073 - accuracy: 0.9509\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 8s 181us/step - loss: 0.0068 - accuracy: 0.9549\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 7s 170us/step - loss: 0.0069 - accuracy: 0.9539\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 0.0067 - accuracy: 0.9555\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 0.0067 - accuracy: 0.9556\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0064 - accuracy: 0.9585\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 0.0067 - accuracy: 0.9558\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0065 - accuracy: 0.9578\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0061 - accuracy: 0.9609\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0063 - accuracy: 0.95840s - loss: 0.006\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0059 - accuracy: 0.9617\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0060 - accuracy: 0.9604\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0065 - accuracy: 0.9565\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0059 - accuracy: 0.9610\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0057 - accuracy: 0.9634\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0056 - accuracy: 0.9632\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0057 - accuracy: 0.9624\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0056 - accuracy: 0.9633\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0056 - accuracy: 0.9635\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0054 - accuracy: 0.9646\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0050 - accuracy: 0.9676\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0056 - accuracy: 0.9635\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 6s 155us/step - loss: 0.0054 - accuracy: 0.9653\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0052 - accuracy: 0.9664\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 6s 155us/step - loss: 0.0050 - accuracy: 0.96780s - loss: 0.0050 - accuracy: \n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0050 - accuracy: 0.9676\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0048 - accuracy: 0.9692\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0051 - accuracy: 0.9667\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0048 - accuracy: 0.9690\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0048 - accuracy: 0.9689\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0048 - accuracy: 0.9697\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 6s 148us/step - loss: 0.0048 - accuracy: 0.9693\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0048 - accuracy: 0.9690\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0047 - accuracy: 0.9695\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 6s 149us/step - loss: 0.0044 - accuracy: 0.9716\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0046 - accuracy: 0.9701\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0045 - accuracy: 0.9718\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 6s 151us/step - loss: 0.0046 - accuracy: 0.9700\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 6s 149us/step - loss: 0.0044 - accuracy: 0.9717\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0043 - accuracy: 0.9720\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 6s 151us/step - loss: 0.0043 - accuracy: 0.9720\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 0.0041 - accuracy: 0.9739\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0043 - accuracy: 0.9720\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0043 - accuracy: 0.9725\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0041 - accuracy: 0.9739\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0042 - accuracy: 0.9724\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0041 - accuracy: 0.9731\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0037 - accuracy: 0.9768\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0039 - accuracy: 0.9750\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0041 - accuracy: 0.9736\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0040 - accuracy: 0.9748\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0039 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 6s 151us/step - loss: 0.0039 - accuracy: 0.9745\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0040 - accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "model2 = mlp_model()\n",
    "history = model2.fit(X_train, y_train,batch_size=100, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 86us/step\n"
     ]
    }
   ],
   "source": [
    "results2 = model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8592222332954407\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model1():\n",
    "    model1 = Sequential()\n",
    "    \n",
    "    model1.add(Dense(400, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(rate=1))\n",
    "    model1.add(Dense(300, kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))    \n",
    "    model1.add(Dropout(rate=1))\n",
    "    model1.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(rate=1))\n",
    "    model1.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(rate=1))\n",
    "    model1.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model1.add(Activation('softmax'))\n",
    "    \n",
    "    \n",
    "    model1.compile(optimizer = 'adam', loss = 'MSE', metrics = ['accuracy'])\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.0553 - accuracy: 0.5653\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0382 - accuracy: 0.7180\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 6s 155us/step - loss: 0.0329 - accuracy: 0.7606\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0293 - accuracy: 0.7888\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0270 - accuracy: 0.8081\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0253 - accuracy: 0.8195\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0234 - accuracy: 0.8325\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0226 - accuracy: 0.8383\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0213 - accuracy: 0.8495\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0204 - accuracy: 0.8565\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0196 - accuracy: 0.8633\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0186 - accuracy: 0.8707\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0180 - accuracy: 0.8730\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0167 - accuracy: 0.8844\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0168 - accuracy: 0.8830\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0158 - accuracy: 0.8899\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0154 - accuracy: 0.8930\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0147 - accuracy: 0.8992\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0141 - accuracy: 0.9036\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0140 - accuracy: 0.9036\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0132 - accuracy: 0.9087\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0130 - accuracy: 0.9114\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0127 - accuracy: 0.9135\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0123 - accuracy: 0.9161\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0120 - accuracy: 0.9188\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0112 - accuracy: 0.9240\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0111 - accuracy: 0.9252\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0109 - accuracy: 0.9263\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0109 - accuracy: 0.9258\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0105 - accuracy: 0.9296\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0103 - accuracy: 0.9300\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0097 - accuracy: 0.9346\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0097 - accuracy: 0.9343\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0095 - accuracy: 0.9365\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0093 - accuracy: 0.9372\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0091 - accuracy: 0.9390\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0088 - accuracy: 0.9420\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0085 - accuracy: 0.9434\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0082 - accuracy: 0.9467\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0082 - accuracy: 0.9464\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.0081 - accuracy: 0.9464\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0079 - accuracy: 0.9482\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0078 - accuracy: 0.9484\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0078 - accuracy: 0.9487\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.0076 - accuracy: 0.9490\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0071 - accuracy: 0.9531\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0073 - accuracy: 0.9529\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.0071 - accuracy: 0.9535\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.0070 - accuracy: 0.9533\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.0069 - accuracy: 0.9549\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 0.0070 - accuracy: 0.9538\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.0067 - accuracy: 0.9565\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0066 - accuracy: 0.9562\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0068 - accuracy: 0.9547\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0062 - accuracy: 0.9596\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0062 - accuracy: 0.9600\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0062 - accuracy: 0.9590\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0061 - accuracy: 0.9597\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0060 - accuracy: 0.9606\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0059 - accuracy: 0.9613\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0061 - accuracy: 0.9602\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0058 - accuracy: 0.9624\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0058 - accuracy: 0.9616\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0057 - accuracy: 0.9626\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 0.0056 - accuracy: 0.9637\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.0056 - accuracy: 0.9638\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0055 - accuracy: 0.9633\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0052 - accuracy: 0.9668\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0053 - accuracy: 0.9659\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 0.0053 - accuracy: 0.9655\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 0.0054 - accuracy: 0.9644\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 7s 166us/step - loss: 0.0053 - accuracy: 0.9659\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 6s 151us/step - loss: 0.0052 - accuracy: 0.9668\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0050 - accuracy: 0.9675\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0051 - accuracy: 0.9668\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0049 - accuracy: 0.9685\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0047 - accuracy: 0.9700\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0049 - accuracy: 0.9691\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0050 - accuracy: 0.9677\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0045 - accuracy: 0.9706\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0046 - accuracy: 0.9700\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0045 - accuracy: 0.97190s - loss: 0.004\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0046 - accuracy: 0.97060s -\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.0046 - accuracy: 0.97071s - los - ETA: 0s - loss: 0.0046 - accura\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0046 - accuracy: 0.9698\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0046 - accuracy: 0.9701\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0042 - accuracy: 0.9730\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.0046 - accuracy: 0.9701\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0043 - accuracy: 0.9720\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0041 - accuracy: 0.9735\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0044 - accuracy: 0.9720\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0044 - accuracy: 0.9713\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.0041 - accuracy: 0.9745\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0043 - accuracy: 0.9725\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0040 - accuracy: 0.9753\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 6s 151us/step - loss: 0.0041 - accuracy: 0.9738\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 6s 151us/step - loss: 0.0041 - accuracy: 0.9737\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 0.0043 - accuracy: 0.9725\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.0040 - accuracy: 0.9742\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.0040 - accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "model3 = mlp_model1()\n",
    "history = model3.fit(X_train, y_train,batch_size=100, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 85us/step\n"
     ]
    }
   ],
   "source": [
    "results3 = model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8539999723434448\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ● Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations) \n",
    "# ● Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) \n",
    "# ● Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f=h5py.File('SVHN_single_grey1.h5','r')\n",
    "# Load Train and test data\n",
    "\n",
    "X_train=h5f['X_train'][:]\n",
    "y_train=h5f['y_train'][:]\n",
    "X_test=h5f['X_test'][:]\n",
    "y_test=h5f['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (42000,) (18000,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# reshaping X data: (n, 28, 28) => (n, 784)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Fully connected layer(linear layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Rectified Linear Activation Layer (ReLU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Cross Entropy Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y]+1e-16)\n",
    "        loss = np.sum(cross_entropy) / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,)\n",
      "(18000,)\n",
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# reshaping X data: (n, 28, 28) => (n, 784)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# # normalize inputs from 0-100 to 0-1\n",
    "train_features = X_train / 100.0\n",
    "test_features = X_test / 100.0\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_train = train_features\n",
    "y_train = y_train\n",
    "\n",
    "X_val = test_features\n",
    "y_val = y_test\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Here, we define the container NN class that enables the forward prop and backward propagation of the entire network. Note, how this class enables us to add layers of different types and also correctly pass gradients using the chain rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc=CrossEntropy(), mode='train'):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        nextgrad = self.loss_func.backward(out,y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return p\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Defining the update function (SGD with momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] - learning_rate * g[i]\n",
    "            p[i] += v[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Defining a function which gives us the minibatches (both the datapoint and the corresponding label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "        \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.The traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
    "    val_loss_epoch = []\n",
    "    #X_val = X_test #test_features\n",
    "    #y_val = y_test\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        # accuracy of model at end of epoch after all mini batch updates\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        y_train_pred = np.array([], dtype=\"int64\")\n",
    "        y_val_pred = np.array([], dtype=\"int64\")\n",
    "        y_train1 = []\n",
    "        y_vall = []\n",
    "        for i in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[i:i + minibatch_size, : ]\n",
    "            y_tr = y_train[i:i + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for i in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[i:i + minibatch_size, : ]\n",
    "            y_va = y_val[i:i + minibatch_size,]\n",
    "            y_vall = np.append(y_vall, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
    "\n",
    "        mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.Checking the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.Invoking all that we have created until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 32.97001997725197 | Training Accuracy = 0.09923809523809524 | Val Loss = 33.34143214655384 | Val Accuracy = 0.10177777777777777\n",
      "Loss = 33.12121392581337 | Training Accuracy = 0.09971428571428571 | Val Loss = 33.34143214655384 | Val Accuracy = 0.10066666666666667\n",
      "Loss = 33.11862962707929 | Training Accuracy = 0.0998095238095238 | Val Loss = 33.525638953993294 | Val Accuracy = 0.10044444444444445\n",
      "Loss = 33.1414361841798 | Training Accuracy = 0.09923809523809524 | Val Loss = 33.34143214655384 | Val Accuracy = 0.10177777777777777\n",
      "Loss = 33.126837857894294 | Training Accuracy = 0.0998095238095238 | Val Loss = 33.525638953993294 | Val Accuracy = 0.10044444444444445\n",
      "Loss = 33.1366413732118 | Training Accuracy = 0.10192857142857142 | Val Loss = 33.525638953993294 | Val Accuracy = 0.0955\n",
      "Loss = 33.16129943586153 | Training Accuracy = 0.09992857142857142 | Val Loss = 31.68357087959807 | Val Accuracy = 0.10016666666666667\n",
      "Loss = 33.08091109031787 | Training Accuracy = 0.09971428571428571 | Val Loss = 33.34143214655384 | Val Accuracy = 0.10066666666666667\n",
      "Loss = 33.06758469565048 | Training Accuracy = 0.10192857142857142 | Val Loss = 33.525638953993294 | Val Accuracy = 0.0955\n",
      "Loss = 33.16087816310792 | Training Accuracy = 0.0998095238095238 | Val Loss = 33.525638953993294 | Val Accuracy = 0.10044444444444445\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## input size\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "## hyperparameters\n",
    "iterations = 10\n",
    "learning_rate = 1e4\n",
    "hidden_nodes = 32\n",
    "output_nodes = 10\n",
    "\n",
    "## define neural net\n",
    "nn = NN()\n",
    "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "nn.add_layer(ReLU())\n",
    "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
    "\n",
    "nn = train(nn, X_train , y_train, minibatch_size=200, epoch=10, \\\n",
    "           learning_rate=learning_rate, X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.fprop a single image and showing its prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18479db4eb8>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[0].reshape(32,32), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Scores for each class\n",
    "prediction = nn.predict_scores(X_val[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class = nn.predict(X_val[0])[0]\n",
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original class\n",
    "y_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=nn.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      0.10      0.18     18000\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     18000\n",
      "   macro avg       0.10      0.01      0.02     18000\n",
      "weighted avg       1.00      0.10      0.18     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(predicted_labels,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "## From above we can conclude that for the given data set ,the classification report from kNN classifier is better than the NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
